{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDDH0lUTNyy_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install chromadb\n",
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3rErMJ6OQgB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import chromadb\n",
        "from google.colab import drive\n",
        "import fasttext\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0k5kXhJP3tR",
        "outputId": "cc8682c8-9f04-4ed3-e327-500087f43116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-29 18:53:48--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.51, 3.163.189.108, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4502524724 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.fa.300.bin.gz’\n",
            "\n",
            "cc.fa.300.bin.gz    100%[===================>]   4.19G   255MB/s    in 22s     \n",
            "\n",
            "2024-02-29 18:54:09 (199 MB/s) - ‘cc.fa.300.bin.gz’ saved [4502524724/4502524724]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "!gunzip /content/cc.fa.300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXjbtisPOVd3",
        "outputId": "93a12a59-681e-4008-8119-18c6db29c503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOV9TMjqKLPp"
      },
      "outputs": [],
      "source": [
        "from drive.MyDrive.nlp.tools import extraction,prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48FBo2JDGG4Q"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./drive/MyDrive/nlp/final_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdAwVFPHSDye",
        "outputId": "4f025578-3eaa-428f-a897-c61c7a40b545"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "ft = fasttext.load_model('cc.fa.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKzxK4BrQWeI"
      },
      "outputs": [],
      "source": [
        "class FasttexEmbeddingtModel(EmbeddingFunction):\n",
        "    def __init__(self, model):\n",
        "      self.model = model\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "      result =  [self.model.get_sentence_vector(doc.replace(\"\\n\", \"\") ).tolist() for doc in input]\n",
        "      return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LdxcIIyV-BQ"
      },
      "outputs": [],
      "source": [
        "embedding_function = FasttexEmbeddingtModel(ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl5vylLHOYXh"
      },
      "outputs": [],
      "source": [
        "chroma_client = chromadb.PersistentClient(path=\"/content/drive/MyDrive/nlp\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SIYDJqcO3FY"
      },
      "outputs": [],
      "source": [
        "collection = chroma_client.get_or_create_collection(name = \"fasttext\",embedding_function=embedding_function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd3eUi4WFyk1",
        "outputId": "56e66b40-5064-441c-f13b-42d7bf19ec4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "item : 0\n",
            "item : 300\n",
            "item : 600\n",
            "item : 900\n",
            "item : 1200\n",
            "item : 1500\n",
            "item : 1800\n",
            "item : 2100\n",
            "item : 2400\n",
            "item : 2700\n",
            "item : 3000\n",
            "item : 3300\n",
            "item : 3600\n",
            "item : 3900\n",
            "item : 4200\n",
            "item : 4500\n",
            "item : 4800\n",
            "item : 5100\n",
            "item : 5400\n",
            "item : 5700\n",
            "item : 6000\n",
            "item : 6300\n",
            "item : 6600\n",
            "item : 6900\n",
            "item : 7200\n",
            "item : 7500\n",
            "item : 7800\n",
            "item : 8100\n",
            "item : 8400\n",
            "item : 8700\n",
            "item : 9000\n",
            "item : 9300\n"
          ]
        }
      ],
      "source": [
        "totall = 0\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    if totall %300 == 0:\n",
        "      print('item :',totall)\n",
        "\n",
        "\n",
        "    ids = [extraction.extrac_id(row)]\n",
        "    text = [prompt.create_promt_embeding(row)]\n",
        "    metadatas = [extraction.meta_data(row)]\n",
        "    collection.add(\n",
        "    documents=text,\n",
        "    metadatas=metadatas,\n",
        "    ids=ids\n",
        "    )\n",
        "    totall += 1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
